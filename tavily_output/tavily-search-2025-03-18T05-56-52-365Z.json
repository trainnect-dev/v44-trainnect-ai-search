{
  "timestamp": "2025-03-18T05:56:52.365Z",
  "query": "Latest news about Qwen QWQ 32B open-source model from January to March 2025 (note: searching for future dates may yield no results; results will reflect available data up to present)",
  "results": {
    "query": "Latest news about Qwen QWQ 32B open-source model from January to March 2025 (note: searching for future dates may yield no results; results will reflect available data up to present)",
    "responseTime": 3.03,
    "images": [],
    "results": [
      {
        "title": "Alibaba's new open source model QwQ-32B matches DeepSeek-R1 ...",
        "url": "https://venturebeat.com/ai/alibabas-new-open-source-model-qwq-32b-matches-deepseek-r1-with-way-smaller-compute-requirements/",
        "content": "Team Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\n\n\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\n\n\n\n\n\nSubscribe Events Video Special Issues Jobs\n\nAlibaba’s new open source model QwQ-32B matches DeepSeek-R1 with way smaller compute requirements\nCarl Franzen@carlfranzen\nMarch 5, 2025 3:06 PM [...] Published Time: 2025-03-05T23:06:56+00:00\nqwq-32b-launches-high-efficiency-performance-reinforcement | VentureBeat\nSkip to main content\nEvents Video Special Issues Jobs\n\nSubscribe\n\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\n\n\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security [...] © 2025 VentureBeat. All rights reserved.\n×",
        "rawContent": null,
        "score": 0.7801967813999999
      },
      {
        "title": "Qwen's QwQ-32B: Small Model with Huge Potential - Analytics Vidhya",
        "url": "https://www.analyticsvidhya.com/blog/2025/03/qwens-qwq-32b/",
        "content": "Published Time: 2025-03-10T04:30:00+00:00\nQwen’s QwQ-32B: Small Model with Huge Potential - Analytics Vidhya\nMaster Generative AI with 10+ Real-world Projects in 2025! Download Projects\n\n\nFree Courses\nLearning Paths\nGenAI Pinnacle Plus Program New\n\nAgentic AI Pioneer Program\n\n\n\n\n\nLogin\nSwitch Mode\nLogout [...] Nitika Sharma Last Updated : 10 Mar, 2025\n4 min read\n0 [...] QwQ-32B is a 32-billion-parameter AI model from the Qwen series. It uses Reinforcement Learning (RL) to improve reasoning and problem-solving skills, performing as well as larger models like DeepSeek-R1. It can adapt its reasoning based on feedback and use tools effectively. The model is open-weight, available on Hugging Face and ModelScope under the Apache 2.0 license, and can be accessed through Qwen Chat. It highlights how RL can boost AI capabilities in meaningful ways.\nPerformance",
        "rawContent": null,
        "score": 0.7308617826566667
      },
      {
        "title": "QwQ-32B: Embracing the Power of Reinforcement Learning - Qwen",
        "url": "https://qwenlm.github.io/blog/qwq-32b/",
        "content": "QwQ-32B: Embracing the Power of Reinforcement Learning | Qwen\n\n\nBlog\nPublication\nAbout\nTry Qwen Chat \n\nQwQ-32B: Embracing the Power of Reinforcement Learning\nMarch 6, 2025 · 4 min · 742 words · Qwen Team | Translations:\n\n简体中文 [...] © 2025 Qwen Powered by Hugo [...] QwQ-32B is open-weight in Hugging Face and ModelScope under the Apache 2.0 license and is accessible via Qwen Chat.\nPerformance#\nQwQ-32B is evaluated across a range of benchmarks designed to assess its mathematical reasoning, coding proficiency, and general problem-solving capabilities. The results below highlight QwQ-32B’s performance in comparison to other leading models, including DeepSeek-R1-Distilled-Qwen-32B, DeepSeek-R1-Distilled-Llama-70B, o1-mini, and the original DeepSeek-R1.",
        "rawContent": null,
        "score": 0.6636600598166666
      },
      {
        "title": "Alibaba Cloud Unveils QwQ-32B: A Compact Reasoning Model with ...",
        "url": "https://www.alibabacloud.com/blog/alibaba-cloud-unveils-qwq-32b-a-compact-reasoning-model-with-cutting-edge-performance_602039",
        "content": "QwQ-32B is now available as an open-source model on Hugging Face and Model Scope under the Apache 2.0 license, allowing free downloads. It is also accessible via Qwen Chat. Thanks to its significantly reduced deployment costs, the model can be efficiently deployed on consumer-grade hardware.\n\n\n\nFor more details about QwQ-32B, visit the official blog post: QwQ-32B: Embracing the Power of Reinforcement Learning.\n\n\n\nThis article was originally published on Alizila written by Crystal Liu. [...] Read previous post:\n\nFlinkSQL Temporary Join Development\n\nAlibaba Cloud Community\n\n1,109 posts | 332 followers\n\nYou may also like\n\nAlibaba Cloud Community - December 2, 2024\n\nAlibaba Cloud Community - January 2, 2025\n\nAlibaba Cloud Community - February 27, 2025\n\nCed - February 17, 2025\n\nFuji - February 25, 2025\n\nAlibaba Cloud Community - September 19, 2024\n\nComments\n\nAlibaba Cloud Community\n\n1,109 posts | 332 followers\n\nRelated Products\n\nTongyi Qianwen (Qwen)",
        "rawContent": null,
        "score": 0.62839527847
      },
      {
        "title": "Alibaba's QWQ 32B: The Compact AI Model That Rivals DeepSeek R1",
        "url": "https://medium.com/@tahirbalarabe2/alibabas-qwq-32b-the-compact-ai-model-that-rivals-deepseek-r-0d7b57d585e2",
        "content": "QWEN-32B is a 32 billion parameter open-source thinking model developed by Alibaba. Its significance lies in its comparable performance to much larger models like DeepSeek R1 (671 billion parameters) while being small enough to run efficiently on standard hardware, even personal computers. This makes it a more accessible and cost-effective solution for various AI applications, especially agent-based tasks.\n\n2. How does QWEN-32B achieve its performance, especially in reasoning and coding? [...] QWEN-32B is particularly well-suited for agent-based tasks and tool calling due to its reasoning capabilities and efficiency. Its speed makes it ideal for applications where quick iterations and real-time responses are crucial. Future directions include integrating agents with reinforcement learning to enable long-horizon reasoning, and exploring techniques like Chain of Draft to optimize its thinking process and reduce token consumption.\n\n--\n\n--\n\nWritten by Tahir\n\nNo responses yet\n\nHelp",
        "rawContent": null,
        "score": 0.50135316585
      }
    ],
    "answer": "Qwen QWQ 32B is an open-source AI model from Alibaba, matching larger models in performance with lower compute needs. It uses reinforcement learning for improved reasoning and is available on Hugging Face and ModelScope."
  }
}